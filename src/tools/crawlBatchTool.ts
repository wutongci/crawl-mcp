import { z } from 'zod';
import { MCPTool } from '../types';
import { CrawlArticleResult } from './crawlArticleTool';

/**
 * æ‰¹é‡å¾®ä¿¡æ–‡ç« æŠ“å–å·¥å…·å®šä¹‰
 */
export const crawlBatchTool: MCPTool = {
    name: 'crawl_wechat_batch',
    description: 'ğŸ”¥ [æ‰¹é‡æ–‡ç« æŠ“å–å™¨] é«˜æ•ˆæ‰¹é‡æŠ“å–å¤šç¯‡å¾®ä¿¡å…¬ä¼—å·æ–‡ç«  - æ”¯æŒå¹¶å‘æ§åˆ¶ã€æ™ºèƒ½å»¶æ—¶ã€æ–­ç‚¹ç»­ä¼ ã€‚é€‚åˆå¤§é‡æ–‡ç« çš„æ‰¹é‡æ”¶é›†å’Œæ•´ç†ã€‚',
    inputSchema: {
        type: 'object',
        properties: {
            urls: {
                type: 'array',
                items: { type: 'string' },
                description: 'è¦æŠ“å–çš„æ–‡ç« URLåˆ—è¡¨'
            },
            concurrent_limit: {
                type: 'integer',
                default: 2,
                description: 'å¹¶å‘æŠ“å–æ•°é‡é™åˆ¶ï¼ˆå»ºè®®2-3ä¸ªï¼‰'
            },
            delay_seconds: {
                type: 'integer',
                default: 5,
                description: 'æ¯æ¬¡æŠ“å–é—´éš”ç§’æ•°ï¼ˆé¿å…è§¦å‘åçˆ¬è™«ï¼‰'
            },
            output_format: {
                type: 'string',
                enum: ['markdown', 'json'],
                default: 'markdown',
                description: 'è¾“å‡ºæ ¼å¼'
            },
            save_images: {
                type: 'boolean',
                default: true,
                description: 'æ˜¯å¦ä¸‹è½½å¹¶æœ¬åœ°åŒ–å›¾ç‰‡èµ„æº'
            },
            clean_content: {
                type: 'boolean',
                default: true,
                description: 'æ˜¯å¦è‡ªåŠ¨æ¸…ç†å¹¿å‘Šå’Œæ— å…³å†…å®¹'
            },
            stop_on_error: {
                type: 'boolean',
                default: false,
                description: 'é‡åˆ°é”™è¯¯æ—¶æ˜¯å¦åœæ­¢æ•´ä¸ªæ‰¹æ¬¡'
            },
            create_summary: {
                type: 'boolean',
                default: true,
                description: 'æ˜¯å¦åˆ›å»ºæ‰¹é‡æŠ“å–æ‘˜è¦æŠ¥å‘Š'
            }
        },
        required: ['urls']
    },
    zodSchema: z.object({
        urls: z.array(z.string().url()).min(1, 'è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªURL').max(50, 'å•æ¬¡æœ€å¤šæ”¯æŒ50ä¸ªURL'),
        concurrent_limit: z.number().int().min(1).max(5).default(2),
        delay_seconds: z.number().int().min(1).max(60).default(5),
        output_format: z.enum(['markdown', 'json']).default('markdown'),
        save_images: z.boolean().default(true),
        clean_content: z.boolean().default(true),
        stop_on_error: z.boolean().default(false),
        create_summary: z.boolean().default(true)
    })
};

/**
 * æ‰¹é‡æŠ“å–å‚æ•°ç±»å‹å®šä¹‰
 */
export interface CrawlBatchParams {
    urls: string[];
    concurrent_limit?: number;
    delay_seconds?: number;
    output_format?: 'markdown' | 'json';
    save_images?: boolean;
    clean_content?: boolean;
    stop_on_error?: boolean;
    create_summary?: boolean;
}

/**
 * æ‰¹é‡æŠ“å–ç»“æœç±»å‹å®šä¹‰
 */
export interface CrawlBatchResult {
    success: boolean;
    total_count: number;
    success_count: number;
    failed_count: number;
    results: CrawlArticleResult[];
    summary_path?: string;
    batch_start_time: Date;
    batch_end_time: Date;
    total_duration: number;
    average_duration: number;
    concurrent_limit_used: number;
    delay_used: number;
    aggregated_stats: {
        total_articles: number;
        total_images: number;
        total_content_size: number;
        success_rate: number;
        fastest_crawl: number;
        slowest_crawl: number;
    };
    errors?: Array<{
        url: string;
        error: string;
        timestamp: Date;
    }>;
    warnings?: string[];
}

/**
 * æ‰¹é‡æŠ“å–è¿›åº¦ä¿¡æ¯
 */
export interface CrawlBatchProgress {
    session_id: string;
    total_urls: number;
    completed_urls: number;
    successful_urls: number;
    failed_urls: number;
    current_url?: string;
    progress_percentage: number;
    estimated_remaining_time?: number;
    start_time: Date;
    elapsed_time: number;
    average_time_per_url: number;
}

/**
 * éªŒè¯æ‰¹é‡æŠ“å–å‚æ•°
 */
export function validateCrawlBatchParams(params: any): CrawlBatchParams {
    try {
        const validated = crawlBatchTool.zodSchema.parse(params);
        
        // é¢å¤–éªŒè¯URLæ ¼å¼
        const invalidUrls = validated.urls.filter((url: string) => !url.includes('mp.weixin.qq.com'));
        if (invalidUrls.length > 0) {
            throw new Error(`ä»¥ä¸‹URLä¸æ˜¯æœ‰æ•ˆçš„å¾®ä¿¡æ–‡ç« URL: ${invalidUrls.join(', ')}`);
        }
        
        return validated;
    } catch (error) {
        if (error instanceof z.ZodError) {
            const messages = error.errors.map(err => `${err.path.join('.')}: ${err.message}`);
            throw new Error(`æ‰¹é‡æŠ“å–å‚æ•°éªŒè¯å¤±è´¥: ${messages.join(', ')}`);
        }
        throw error;
    }
}

/**
 * åˆ›å»ºæ‰¹é‡æˆåŠŸç»“æœ
 */
export function createBatchSuccessResult(
    params: CrawlBatchParams,
    results: CrawlArticleResult[],
    batchInfo: {
        startTime: Date;
        endTime: Date;
        summaryPath?: string;
    }
): CrawlBatchResult {
    const successResults = results.filter(r => r.success);
    const failedResults = results.filter(r => !r.success);
    
    const totalDuration = batchInfo.endTime.getTime() - batchInfo.startTime.getTime();
    const averageDuration = results.length > 0 ? Math.round(totalDuration / results.length) : 0;
    
    // è®¡ç®—èšåˆç»Ÿè®¡
    const totalImages = successResults.reduce((sum, r) => sum + r.images.length, 0);
    const totalContentSize = successResults.reduce((sum, r) => sum + r.content.length, 0);
    const durations = results.map(r => r.duration).filter(d => d > 0);
    const fastestCrawl = durations.length > 0 ? Math.min(...durations) : 0;
    const slowestCrawl = durations.length > 0 ? Math.max(...durations) : 0;
    const successRate = Math.round((successResults.length / results.length) * 100);

    return {
        success: successResults.length > 0,
        total_count: results.length,
        success_count: successResults.length,
        failed_count: failedResults.length,
        results,
        summary_path: batchInfo.summaryPath,
        batch_start_time: batchInfo.startTime,
        batch_end_time: batchInfo.endTime,
        total_duration: totalDuration,
        average_duration: averageDuration,
        concurrent_limit_used: params.concurrent_limit || 2,
        delay_used: params.delay_seconds || 5,
        aggregated_stats: {
            total_articles: successResults.length,
            total_images: totalImages,
            total_content_size: totalContentSize,
            success_rate: successRate,
            fastest_crawl: fastestCrawl,
            slowest_crawl: slowestCrawl
        },
        errors: failedResults.map(r => ({
            url: r.url,
            error: r.error || 'æœªçŸ¥é”™è¯¯',
            timestamp: r.crawl_time
        })),
        warnings: []
    };
}

/**
 * åˆ›å»ºæ‰¹é‡é”™è¯¯ç»“æœ
 */
export function createBatchErrorResult(
    params: CrawlBatchParams,
    error: string,
    partialResults: CrawlArticleResult[] = []
): CrawlBatchResult {
    const successResults = partialResults.filter(r => r.success);
    const failedResults = partialResults.filter(r => !r.success);

    return {
        success: false,
        total_count: params.urls.length,
        success_count: successResults.length,
        failed_count: params.urls.length - successResults.length,
        results: partialResults,
        batch_start_time: new Date(),
        batch_end_time: new Date(),
        total_duration: 0,
        average_duration: 0,
        concurrent_limit_used: params.concurrent_limit || 2,
        delay_used: params.delay_seconds || 5,
        aggregated_stats: {
            total_articles: successResults.length,
            total_images: 0,
            total_content_size: 0,
            success_rate: 0,
            fastest_crawl: 0,
            slowest_crawl: 0
        },
        errors: [{
            url: 'batch_operation',
            error,
            timestamp: new Date()
        }],
        warnings: []
    };
}

/**
 * åˆ›å»ºè¿›åº¦ä¿¡æ¯
 */
export function createProgressInfo(
    sessionId: string,
    params: CrawlBatchParams,
    completed: number,
    successful: number,
    failed: number,
    startTime: Date,
    currentUrl?: string
): CrawlBatchProgress {
    const totalUrls = params.urls.length;
    const elapsedTime = Date.now() - startTime.getTime();
    const averageTimePerUrl = completed > 0 ? Math.round(elapsedTime / completed) : 0;
    const remainingUrls = totalUrls - completed;
    const estimatedRemainingTime = remainingUrls > 0 && averageTimePerUrl > 0 
        ? remainingUrls * averageTimePerUrl 
        : undefined;

    return {
        session_id: sessionId,
        total_urls: totalUrls,
        completed_urls: completed,
        successful_urls: successful,
        failed_urls: failed,
        current_url: currentUrl,
        progress_percentage: Math.round((completed / totalUrls) * 100),
        estimated_remaining_time: estimatedRemainingTime,
        start_time: startTime,
        elapsed_time: elapsedTime,
        average_time_per_url: averageTimePerUrl
    };
} 